### 10.1 立方体纹理

- 环境映射可以模拟物体周围的环境，而使用了环境映射的物体可以看起来像镀了层金属一样反射出周围的环境。

- 立方体纹理是环境映射的一种实现方法。一共包含了6张图像，这些图像对应了一个立方体的6个面，每个面表示沿着世界空间中的轴向（x，y，z正负轴）观察所得的图像。对立方体纹理采样需要提供一个三维的纹理坐标，该坐标表示从立方体的中心出发，当它向外部延伸时就会和立方体的6个纹理之一相交，采样的结果就是该交点

- 使用立方体纹理的好处：实现简单快速，得到的效果也比较好。

  缺点：当场景中引入新的物体、光源或物体发生移动时需要重新生成立方体纹理，且立方体纹理仅可以反射环境，但不能反射使用了该立方体纹理的物体本身，因为立方体纹理不能模拟多次反射的结果，所以尽量对凸面体而不要对凹面体使用立方体纹理，因为凹面体会反射本省

#### 10.1.1 天空盒子

- 天空盒子是游戏中用于模拟背景的一种方法，当在场景中使用时，整个场景就被包围在一个立方体内，该立方体使用的技术就是立方体纹理映射技术

- 在Unity中使用天空盒子非常简单，只需要创建一个天空盒子材质，选择Shader为自带的Skybox->6 sided，然后为六个面附上纹理，需要将纹理的Wrap Mode设置为Clamp防止在接缝处出现不匹配现象。

  可以在Window->Rendering->Light setting中的Skybox Material中赋值。该赋值会应用于场景中的所有摄像机，也可在摄像机上添加Skybox组件然后赋予材质以覆盖默认的天空盒

- 在Unity中，天空盒是在所有不透明物体之后渲染的，其背后使用的网格是一个立方体或一个细分后的球体

#### 10.1.2 创建用于环境映射的立方体纹理

- 在unity中创建用于环境映射的立方体纹理方法有三种：
  1. 直接由一些特殊布局的纹理创建，如类似立方体张开图的交叉布局、全景布局等，将该纹理的Texture Type设置为Cubemap即可，Unity会处理剩下的事。在基于物理的渲染中，通常会使用一张HDR图像来生成高质量的Cubemap。官方推荐使用该功能，因为可以对纹理数据进行压缩，且支持边缘修正、光滑反射、以及HDR
  2. 手动创建一个Cubemap的资源，再将6张图赋给它。在Unity 5前使用的方法
  3. 由脚本生成。Camera.RenderToCubemap函数可以把任意位置观察到的场景图像存储到6张图像中，从而创建出该位置上对应的立方体纹理。为了将图像存储在纹理中，需要在创建的立方体纹理面板中勾选Readable选项

#### 10.1.3 反射

-   模拟反射效果只需要通过入射光线的方向和表面法线方向来计算反射方向，再利用反射方向对立方体纹理采样即可

```c++
Shader "Unity Shaders Book/Chapter 10/Reflection"{
	Properties{
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
        // 反射颜色
		_ReflectColor ("Reflection Color", Color) = (1, 1, 1, 1)
        // 反射程度
		_ReflectAmount ("Reflect Amount", Range(0, 1)) = 1
		_Cubemap ("Reflection Cubemap", Cube) = "_Skybox" {}
	}
	
	SubShader{
		Tags { "RenderType" = "Opaque" "Queue" = "Geometry"}
		Pass{
			Tags { "LightMode" = "ForwardBase" }

			CGPROGRAM

			#pragma multi_compile_fwdbase

			#pragma vertex vert 
			#pragma fragment frag 

			#include "Lighting.cginc"
			#include "AutoLight.cginc"

			fixed4 _Color;
			fixed4 _ReflectColor;
			fixed _ReflectAmount;
			samplerCUBE _Cubemap;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldPos : TEXCOORD0;
				fixed3 worldNormal : TEXCOORD1;
				fixed3 worldViewDir : TEXCOORD2;
				fixed3 worldRefl : TEXCOORD3;
				SHADOW_COORDS(4)
			};
			
			v2f vert(a2v v){
				v2f o;

				o.pos = UnityObjectToClipPos(v.vertex);
				o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
				o.worldNormal = normalize(UnityObjectToWorldNormal(v.normal));
				o.worldViewDir = normalize(UnityWorldSpaceViewDir(o.worldPos));
				o.worldRefl = reflect(-o.worldViewDir, o.worldNormal);

				return o;
			}

			fixed4 frag(v2f i) : SV_Target{
				fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
				
				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

				fixed diffuse = _LightColor0.rgb * _Color.rgb * saturate(dot(i.worldNormal, worldLightDir));

				// 因为立方体纹理使用方向作为采样，所以不需要归一化
				fixed3 reflection = texCUBE(_Cubemap, i.worldRefl).rgb * _ReflectColor.rgb;

				UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);
				
				fixed3 color = ambient + lerp(diffuse, reflection, _ReflectAmount) * atten;

				return fixed4(color, 1.0);
			}
			ENDCG
		}
	}
	FallBack "Reflective/VertexLit"
}
```

#### 10.1.4 折射

- 斯涅尔定律（Snell's Law）：当光从一个介质斜射入另一个介质时
  $$
  k_1sin\theta_1 = k_2sin\theta_2
  $$
  其中k1、k2是两个介质的折射率，两个角都是沿表面法线的夹角

- 通常来说当得到折射方向后悔直接使用来对立方体纹理进行采样，但这不符合物理规律。对一个透明物体来说，更准确的模拟方法需要计算两次折射，一次是当其进入物体内部，另一次是从内部折射出。但在试试渲染中模拟出第二次折射方向是比较复杂的，所以在实时渲染中通常仅模拟第一次折射

```c++
Shader "Unity Shaders Book/Chapter 10/Refraction"{
	
	Properties{
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		// 折射颜色
		_RefractColor ("Refraction Color", Color) = (1, 1, 1, 1)
		// 材质的折射程度
		_RefractAmount ("Refraction Amount", Range(0, 1)) = 1
		// 不同介质的折射比
		_RefractRatio ("Refraction Ratio", Range(0.1, 1)) = 0.5
		_Cubemap ("Refraction CubeMap", Cube) = "_Skybox" {}
	}

	SubShader{
		Tags { "RenderType" = "Opaque" "Queue" = "Geometry" }

		Pass{
			Tags { "LightMode" = "ForwardBase" }

			CGPROGRAM

			#pragma multi_compile_fwdbase

			#pragma vertex vert 
			#pragma fragment frag 

			#include "Lighting.cginc"
			#include "AutoLight.cginc"

			fixed4 _Color;
			fixed4 _RefractColor;
			fixed _RefractAmount;
			fixed _RefractRatio;
			samplerCUBE _Cubemap;

			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldPos : TEXCOORD0;
				fixed3 worldNormal : TEXCOORD1;
				fixed3 worldViewDir : TEXCOORD2;
				fixed3 worldRefr : TEXCOORD3;
				SHADOW_COORDS(4)
			};

			v2f vert(a2v v){
				v2f o;

				o.pos = UnityObjectToClipPos(v.vertex);
				o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
				o.worldNormal = UnityObjectToWorldNormal(v.normal);
				o.worldViewDir = normalize( UnityWorldSpaceViewDir(o.worldPos));
				o.worldRefr = refract(-o.worldViewDir, normalize(o.worldNormal), _RefractRatio);

				TRANSFER_SHADOW(o);

				return o;
			}

			fixed4 frag(v2f i) : SV_Target{
				fixed3 worldNormal = normalize(i.worldNormal);
				fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
				
				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

				fixed3 diffuse = _LightColor0.rgb * _Color.rgb * saturate(dot(worldNormal, worldLightDir));

				fixed3 refraction = texCUBE(_Cubemap, i.worldRefr).rgb * _RefractColor.rgb;

				UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);
				// 混合
				fixed3 color = ambient + lerp(diffuse, refraction, _RefractAmount) * atten;
				return fixed4(color, 1.0);
			}

			ENDCG
		}
		
	}
	FallBack "Reflective/VertexLit"
}
```

#### 10.1.5 菲涅尔反射

- 菲涅尔反射描述了一种光学现象，即当光线照射到物体表面上时，一部分发生反射，一部分进入物体内部发生折射或反射。被反射的光和入射光之间存在一定比率关系，该关系可以通过菲涅尔等式进行计算

- 真实世界的菲涅尔等式是非常复杂的，实时渲染中通常使用一些近似的公式计算，其中著名的一个就是Schlick菲涅尔近似等式：

  F0是反射系数，v是视角方向，n是表面法线
  $$
  F_{Schlick}(v, n) = F_0 + (1-F_0)(1-v\cdot{}n)
  $$
  另一个应用比较广泛的等式是Empricial菲涅尔近似等式：
  $$
  F_{Empricial}(v, n) = max(0, min(1, bias + scale*(1-v\cdot{}n)^{power}))
  $$

```c++
Shader "Unity Shaders Book/Chapter 10/Fresnel"{

	Properties{
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_FresnelScale ("Fresnel Scale", Range(0, 1)) = 0.5
		_Cubemap ("Reflection Cubemap", Cube) = "_Skybox" {}
	}

	SubShader{
		Tags { "RenderType"="Opaque" "Queue"="Geometry"}

		Pass{
			Tags { "LightMode" = "ForwardBase" }

			CGPROGRAM
				
			#pragma multi_compile_fwdbase

			#pragma vertex vert 
			#pragma fragment frag 
			
			#include "Lighting.cginc"
			#include "AutoLight.cginc"

			fixed4 _Color;
			fixed _FresnelScale;
			samplerCUBE _Cubemap;

			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldPos : TEXCOORD0;
  				fixed3 worldNormal : TEXCOORD1;
  				fixed3 worldViewDir : TEXCOORD2;
  				fixed3 worldRefl : TEXCOORD3;
 	 			SHADOW_COORDS(4)
			};

			v2f vert(a2v v){
				v2f o;

				o.pos = UnityObjectToClipPos(v.vertex);
				o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
				o.worldNormal = normalize(UnityObjectToWorldNormal(v.normal));
				o.worldViewDir = normalize(UnityWorldSpaceViewDir(o.worldPos));
				o.worldRefl = reflect(-o.worldViewDir, o.worldNormal);

				TRANSFER_SHADOW(o);

				return o;
			}

			fixed4 frag(v2f i) : SV_Target{
				fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));

				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

				fixed3 diffuse = _LightColor0.rgb * _Color.rgb * saturate(dot(i.worldNormal, worldLightDir));

				fixed3 reflection = texCUBE(_Cubemap, i.worldRefl).rgb;
				// 菲涅尔反射
				fixed fresnel = saturate(_FresnelScale + (1 - _FresnelScale) * pow(1 - dot(i.worldViewDir, i.worldNormal), 5));
				
				UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

				fixed3 color = ambient + lerp(diffuse, reflection, fresnel) * atten;
				return fixed4(color, 1.0);
			}

			ENDCG
		}
	}
	FallBack "Reflective/VertexLit"
}
```

### 10.2 渲染纹理

- 现代的GPU允许把整个三维场景渲染到一个中间缓冲，即渲染目标纹理（Render Target Texture，RTT），而不会传统的帧缓冲或后备缓冲中。与之相关的是多重渲染目标（Multiple Render Target，MRT） ，该技术指GPU允许把场景同时渲染到多个目标纹理中，而不再需要为每个渲染目标纹理单独渲染完整的场景。延迟渲染就是使用多重渲染目标的一个应用
- Unity为渲染目标纹理定义了专门的纹理类型：渲染纹理。Unity中使用渲染纹理通常有两种方式：
  1. 在Project目录下创建一个渲染纹理，然后把某个摄像机的渲染目标设置成该渲染纹理，该摄像机的渲染结果会实时更新到渲染纹理中，而不会显示到屏幕上
  2. 在屏幕后处理时使用CrabPass命令或OnRenderImage函数来获取当前屏幕图像，Unity会把这个屏幕图像放到一张和屏幕分辨率等同的渲染纹理中，之后就可以在自定义的Pass中把它们当成普通的纹理来处理，从而实现各种屏幕特效

#### 10.2.1 镜子效果

- 将摄像机的渲染目标改为RenderTexture，在一个物体上显示该目标即可。但该镜子效果不符合实际

```
Shader "Unity Shaders Book/Chapter 10/Mirror"{
	Properties{
		_MainTex ("Main Tex", 2D) = "white" {}
	}

	SubShader{
		Tags { "RenderType"="Opaque" "Queue"="Geometry"}

		Pass{
			Tags { "LightMode" = "ForwardBase" }

			CGPROGRAM

			#pragma vertex vert 
			#pragma fragment frag 

			sampler2D _MainTex;

			struct a2v {
				float4 vertex : POSITION;
				float3 texcoord : TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float2 uv : TEXCOORD0;
			};

			v2f vert(a2v v){
				v2f o;

				o.pos = UnityObjectToClipPos(v.vertex);
				o.uv = v.texcoord;
				// 镜子的x轴需要翻转
				o.uv.x = 1 - o.uv.x;

				return o;
			}

			fixed4 frag(v2f i) : SV_Target{
				return tex2D(_MainTex, i.uv);
			}
			ENDCG
		}
	}
 	FallBack Off
}
```

#### 10.2.2 玻璃效果

- 当GrabPass，Unity会把当前屏幕的图像绘制在一张纹理中，以便在后续的Pass中访问。通常使用GrabPass实现诸如玻璃等透明材质的模拟，其和简单的透明混合不同，可以对该物体后面的图像进行更复杂的处理，如使用法线模拟折射效果
- 在使用GrabPass时需要小心物体的渲染队列设置，因为常用于渲染透明物体，尽管代码中不包含混合指令，但往往需要把渲染队列设置成透明队列，这样才能保证渲染该物体时所有的不透明物体都已经被绘制在屏幕上
- GrabPass支持两种形式：
  1. 直接使用GrabPass{}，然后在后续的Pass中使用_GrabTexture访问屏幕图像，但当场景中有多个物体使用该形式抓取屏幕时，该方法性能消耗较大。其对每个使用它的物体都单独进行一次昂贵的屏幕抓取操作。但该方法可以让每个物体得到不同的屏幕图像，这取决于它们的渲染队列及渲染它们时的屏幕缓冲颜色
  2. 使用GrabPass{ "TextureName" }，在后续Pass中使用TextureName访问屏幕图像。Unity只会在每一帧时为第一个使用名为TextureName的纹理的物体执行一次抓取屏幕的操作，且该纹理同样可以在其他Pass中被访问。但也意味着所有物体都会使用同一张屏幕图像

```c++
Shader "Unity Shaders Book/Chapter 10/Glass Refraction"{
	
	Properties {
		// 玻璃的材质纹理
		_MainTex ("Main Tex", 2D) = "white" {}
		// 法线纹理
		_BumpMap ("Normal Map", 2D) = "bump" {}
		// 模拟反射的环境纹理
		_Cubemap ("Environment Cubemap", Cube) = "_Skybox" {}
		// 控制折射时图像的扭曲程度
		_Distortion ("Distortion", Range(0, 100)) = 10
		// 控制折射程度。为0时只包含反射效果，为1时只包含折射效果
		_RefractAmount ("Refract Amount", Range(0.0, 1.0)) = 1.0
	}

	SubShader{
		Tags{ "RenderType" = "Opaque" "Queue" = "Transparent"}

		// 获取屏幕图像，该字符串的名称决定了抓取到的屏幕图像放在哪个纹理中。可以省略该字符串，但写出可以提高性能
		GrabPass { "_RefractionTex" }

		Pass{
			Tags {}
			CGPROGRAM

			#pragma vertex vert 
			#pragma fragment frag 

			#include "UnityCG.cginc"

			sampler2D _MainTex;
			float4 _MainTex_ST;
			sampler2D _BumpMap;
			float4 _BumpMap_ST;
			samplerCUBE _Cubemap;
			float _Distortion;
			fixed _RefractAmount;
			// 对应了抓取屏幕的纹理名称
			sampler2D _RefractionTex;
			// 获取纹理的纹素大小,当一个纹理大小为4*5，纹素大小为(1/4,1/5)
			float4 _RefractionTex_TexelSize;

			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
				float4 tangent : TANGENT; 
				float2 texcoord: TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float4 scrPos : TEXCOORD0;
				float4 uv : TEXCOORD1;
				float4 TtoW0 : TEXCOORD2;  
			    float4 TtoW1 : TEXCOORD3;  
			    float4 TtoW2 : TEXCOORD4; 
			};

			v2f vert(a2v v){
				v2f o;

				o.pos = UnityObjectToClipPos(v.vertex);
				// 对应被抓取的屏幕图像的采样坐标，针对不同平台差异造成的采样坐标问题进行了处理
				o.scrPos = ComputeGrabScreenPos(o.pos);

				o.uv.xy = TRANSFORM_TEX(v.texcoord, _MainTex);
				o.uv.zw = TRANSFORM_TEX(v.texcoord, _BumpMap);

				float3 worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
				float3 worldNormal = UnityObjectToWorldNormal(v.normal);
				fixed3 worldTangent = UnityObjectToWorldDir(v.tangent.xyz);
				fixed3 worldBinormal = cross(worldNormal, worldTangent) * v.tangent.w;

				// 计算从切线空间到世界空间的坐标矩阵
				o.TtoW0 = float4(worldTangent.x, worldBinormal.x, worldNormal.x, worldPos.x);
				o.TtoW1 = float4(worldTangent.y, worldBinormal.y, worldNormal.y, worldPos.y);
				o.TtoW2 = float4(worldTangent.z, worldBinormal.z, worldNormal.z, worldPos.z);

				return o;
			}

			fixed4 frag(v2f i) : SV_Target{
				float3 worldPos = float3(i.TtoW0.w, i.TtoW1.w, i.TtoW2.w);
				fixed3 worldViewDir = normalize(UnityWorldSpaceViewDir(worldPos));

				fixed3 bump = UnpackNormal(tex2D(_BumpMap, i.uv.zw));
				
				// 对采样结果进行偏移，模拟折射效果
				// 这里使用切线空间下的法线方向进行偏移，因为该空间下的法线可以反应顶点局部空间下的法线方向
				float2 offset = bump.xy * _Distortion * _RefractionTex_TexelSize.xy;
				i.scrPos.xy = offset * i.scrPos.z + i.scrPos.xy;
				// 进行透视触发得到整整的屏幕坐标，使用改坐标对抓取的屏幕图像进行采样得到折射颜色
				fixed3 refrCol = tex2D(_RefractionTex, i.scrPos.xy/i.scrPos.w).rgb;

				bump = normalize(half3(dot(i.TtoW0.xyz, bump), dot(i.TtoW1.xyz, bump), dot(i.TtoW2.xyz, bump)));
				fixed3 reflDir = reflect(-worldViewDir, bump);
				fixed4 texColor = tex2D(_MainTex, i.uv.xy);
				fixed3 reflCol = texCUBE(_Cubemap, reflDir).rgb * texColor.rgb;
				// 对折射颜色和反射颜色进行混合
				fixed3 color = reflCol * (1 - _RefractAmount) + refrCol * _RefractAmount;
			
				return fixed4(color, 1.0);
			}

			ENDCG
		}
	}
	FallBack "Diffuse"
}
```

#### 10.2.3 渲染纹理 vs GrabPass

- GrabPass与渲染纹理的区别：
  1. GrabPass实现简单，只需在Shader写几行代码就可以实现抓取屏幕。而渲染纹理需要先创建一个渲染纹理和一个额外的摄像机，再把该摄像机的Render Target设置为新建的渲染纹理对象，最后把该渲染纹理传递给相应的Shader
  2. 从效率上讲，渲染纹理要好于GrabPass，尤其在移动设备上。使用渲染纹理可以自定义渲染纹理的大小，尽管该方法需要把部分场景再次渲染一遍，但可以通过调整摄像机的渲染层来减少二次渲染时的场景大小或使用其他方法控制摄像机是否需要开启。而使用GrabPass获取到的图像分辨率和显示屏幕是一致的，意味着在高分辨率的设备上可能会造成严重的带宽影响，且在移动设备上虽然不会重新渲染场景，但往往需要CPU直接读取后备缓冲（back buffer）中的数据，破坏了CPU和GPU的并行性，是比较耗时的，甚至在一些移动设备上不支持
- Unity 5之后引入了命令缓冲（Command Buffers），允许扩展UNity的渲染流水线。使用命令缓冲可以得到类似抓平的效果，可以在不透明物体渲染后把当前的图像复制到一个临时的渲染目标纹理中，然后进行一些额外的操作，最后把图像传递给需要使用它的物体处理和显示。此外命令缓冲还允许实现很多特殊的效果

### 10.3 程序纹理

- 程序纹理指由计算算计生成的图像，通常使用一些特定的算法创建个性化图案或非常真实的自然元素。使用程序纹理在于可以使用各种参数控制纹理的外观，这些属性不仅仅是颜色属性，甚至可以是完全不同类型的图案属性，可以得到更加丰富的动画和世界效果

#### 10.3.1 在Unity中实现简单的程序纹理

```c#
using UnityEngine;

// 保证在编辑器模式下运行
[ExecuteInEditMode]
public class ProceduralTextureGeneration : MonoBehaviour
{
    public Material material = null;

    #region Material properties
    // 纹理大小
    [SerializeField, SetProperty("TextureWidth")]
    private int m_textureWidth = 512;
    public int TextureWidth
    {
        get
        {
            return m_textureWidth;
        }
        set
        {
            m_textureWidth = TextureWidth;
            _UpdateMaterial();
        }
    }

    // 纹理的背景颜色
    [SerializeField, SetProperty("BackgroundColor")]
    private Color m_backgroundColor = Color.white;
    public Color BackgroundColor
    {
        get
        {
            return m_backgroundColor;
        }
        set
        {
            m_backgroundColor = BackgroundColor;
            _UpdateMaterial();
        }
    }

    // 圆点颜色
    [SerializeField, SetProperty("CircleColor")]
    private Color m_circleColor = Color.yellow;
    public Color CircleColor
    {
        get
        {
            return m_circleColor;
        }
        set
        {
            m_circleColor = CircleColor;
            _UpdateMaterial();
        }
    }

    // 模糊因子：模糊原型边界
    [SerializeField, SetProperty("BlurFactor")]
    private float m_blurFactor = 2.0f;
    public float BlurFactor
    {
        get
        {
            return m_blurFactor;
        }
        set
        {
            m_blurFactor = BlurFactor;
            _UpdateMaterial();
        }
    }
    #endregion

    private Texture2D m_generatedTexture = null;

    private void _UpdateMaterial()
    {
        if(material != null)
        {
            m_generatedTexture = _GenerateProceduralTexture();
            material.SetTexture("_MainTex", m_generatedTexture);
        }
    }

    private Texture2D _GenerateProceduralTexture()
    {
        Texture2D proceduralTexture = new Texture2D(TextureWidth, TextureWidth);

        // 圆与圆之间的间距
        float circleInterval = TextureWidth / 4.0f;
        // 圆的半径
        float radius = TextureWidth / 10.0f;
        // 模糊系数
        float edgeBlur = 1.0f / BlurFactor;

        for(int w = 0; w < TextureWidth; w++)
        {
            for(int h = 0; h < TextureWidth; h++)
            {
                // 用背景颜色进行初始化
                Color pixel = BackgroundColor;

                // 画9个圆
                for(int i = 0; i < 3; i++)
                {
                    for(int j = 0; j < 3; j++)
                    {
                        // 计算当前绘制的圆的圆心位置
                        Vector2 circleCenter = new Vector2(circleInterval * (i + 1), circleInterval * (j + 1));
                        // 计算当前像素与圆心的距离
                        float dist = Vector2.Distance(new Vector2(w, h), circleCenter) - radius;
                        // 模糊圆的边界
                        Color color = Color.Lerp(CircleColor, new Color(pixel.r, pixel.g, pixel.b, 0.0f), Mathf.SmoothStep(0.0f, 1.0f, dist * edgeBlur));
                        // 与之前的颜色进行混合
                        pixel = Color.Lerp(pixel, color, color.a);
                    }
                }
                proceduralTexture.SetPixel(w, h, pixel);
            }
        }
        proceduralTexture.Apply();
        return proceduralTexture;
    }

    void Start()
    {
        if(material == null)
        {
            Renderer renderer = gameObject.GetComponent<Renderer>();
            if(renderer == null)
            {
                Debug.LogWarning("Cannot find a renderer.");
                return;
            }

            material = renderer.sharedMaterial;
        }
        _UpdateMaterial();
    }
}
```

#### 10.3.2 Unity的程序材质

- Unity中有一类专门使用程序纹理的材质，叫程序材质。这类材质在本质上和其他的是一样的，不同的是其使用的纹理不是普通的纹理，而是程序纹理。程序材质和其使用的程序纹理并不是在Unity中创建的，而是使用一个名为Substance Designer的软件在外部生成的，当将这些文件导入Unity后，Unity就会生成一个程序纹理资源，程序纹理资源可以包含一个或多个程序材质
